# -*- coding: utf-8 -*-
"""imagegenerator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zfj3EOHAC9k69Yi_3a9jmZervwnbBbNO
"""

# Check GPU
!nvidia-smi || echo "No GPU found. You can still run on CPU, but it will be slow."

# Install deps
!pip -q install --upgrade diffusers transformers accelerate torch torchvision torchaudio safetensors pillow

import torch
from diffusers import StableDiffusionPipeline

device = "cuda" if torch.cuda.is_available() else "cpu"

# You can switch to another public model id if you like.
model_id = "runwayml/stable-diffusion-v1-5"

pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    torch_dtype=torch.float16 if device == "cuda" else torch.float32,
    safety_checker=None,            # disable HF safety checker (still follow local laws/content rules)
    use_safetensors=True
)

# Speed/VRAM tweaks
if device == "cuda":
    pipe = pipe.to("cuda")
    pipe.enable_xformers_memory_efficient_attention()
    pipe.enable_model_cpu_offload()  # ok to keep; it will manage VRAM better
else:
    pipe = pipe.to("cpu")

print(f"Ready on: {device}")

from PIL import Image
import os, time

os.makedirs("/content/outputs", exist_ok=True)

prompt = "a cozy cyberpunk cafe at night, neon reflections, cinematic lighting, ultra-detailed"
negative_prompt = "low quality, blurry, deformed, watermark, text"
seed = 12345
guidance_scale = 7.5
steps = 30
width, height = 768, 512

generator = torch.Generator(device=device).manual_seed(seed)

image = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=steps,
    guidance_scale=guidance_scale,
    width=width,
    height=height,
    generator=generator
).images[0]

ts = int(time.time())
save_path = f"/content/outputs/sd15_{ts}.png"
image.save(save_path)
display(image)
print("Saved to:", save_path)

prompts = [
    "a futuristic city skyline at dawn, volumetric light, highly detailed",
    "a macro shot of a dew-covered leaf, photorealistic, shallow depth of field",
    "a whimsical isometric village, pastel palette, cozy atmosphere"
]

images = pipe(
    prompt=prompts,
    negative_prompt=["low quality, blurry"] * len(prompts),
    num_inference_steps=30,
    guidance_scale=7.5
).images

for i, img in enumerate(images):
    path = f"/content/outputs/batch_{i}.png"
    img.save(path)
    display(img)
    print("Saved:", path)